{\rtf1\ansi\ansicpg1252\deff0\nouicompat\deflang1033{\fonttbl{\f0\fnil\fcharset0 Bahnschrift SemiBold SemiConden;}{\f1\fnil\fcharset0 Calibri;}{\f2\fnil Calibri;}{\f3\fnil\fcharset1 Cambria Math;}}
{\*\generator Riched20 10.0.25211}{\*\mmathPr\mmathFont3\mwrapIndent1440 }\viewkind4\uc1 
\pard\sa200\sl276\slmult1\qc\b\f0\fs22\lang9 LITERATURE SURVEY ON HEART DISEASE PREDICTION\b0\f1\par

\pard\sa200\sl276\slmult1 Abstract: Heart Disease is the one of major causes of death globally. Around17.9millionpeopledie each year. Cardiovascular diseases include disorders of the heart and bloodvessels. Fouroutoffive cardiovascular disease deaths are due to heart attacks. One-third of thesedeathsoccurprematurely under the age of seventy. The major number of deaths have occurredindevelopingcountries. India is one of them. For heart disease diagnosis we need cardiologists, which are in limited number indevelopingcountries. Also, the tests for cardiovascular diseases are quite expensive; sometimesoutofthebudget for common people. Early detection is important in case of heart diseasewithlessexpensive prediction techniques. As we know, now-a-days Machine Learning algorithmsareusedfor predicting various diseases. They are also used for predicting Heart Disease. Thispaperdealswith the survey of Machine Learning algorithms used for predicting heart disease, theimportanceof attributes to predict the disease and selection of important attributes for predication. I.INTRODUCTION\par
Machine learning (ML) is the subdomain of artificial intelligence (AI). Today we are using MLindaytodaylife.ML based computer programs can access data and use it to learn themselves. It means past experienceisusedforprediction in ML. ML algorithms are of four types: Supervised Learning in which direct supervisionisinvolveddeveloper label the dataset restricts the boundaries of algorithm, Unsupervised Learning supervisionisnotrequired,semi supervised machine learning both type supervised and unsupervised used in combineformatandReinforcement Learning exploration of thing one by one fist event take as input for next event. Inthispaperthefocusis on supervised machine learning algorithms. In supervised machine learning algorithms, as the name indicate there is presence of a supervisor whotrainthemachine for prediction. In other words we train the machine with the help of a labeled dataset. Labelleddatasetisthe one which is tagged with the correct answeror class which can be labeled after predictedbymachine.Inourprediction system, we are predicting the labelled data into two categories:having a heart diseaseor not havingaheart disease. Heart disease dataset from UCI machine learning repository is used. This datasetcontain76various attributes and 303 instances. Attribute selection is an important factor for the accuracyof resultasmorerelevant datacan predict results accurately. Selection of attributes from the dataset needs proper domainknowledgethat can help select fewer attributesto predict results accurately. Out of the 76 attributes present intheClevelandHeart disease dataset, 14 attributes are selected for predictionIn Cleveland Heart disease dataset for sixinstancessome values are missing. The remaining 297 instances have complete values.Hence most of the researchers use the 297 instance values for prediction of heart disease. For machinelearningsizeof the data set is an important point for the accuracy of the model. Bigger size dataset with data without noiseanddata with no missing values are usefully reliable. But we face problem if the dataset size is small. Forbetteraccuracy, more pattern in the dataset should be explored. The cross- validation is used for it. For any supervise Machine Learning algorithm dataset is divided in two-parts: first one is trainingpart andthesecond one is the testingpart. Commonly training size is 70% and testing size is 30%but for special analysissizemay vary. In general training using larger amount of data and testing against a small amount of dataaccountforaccuracy of a ML algorithm. As shown in Fig. 2, the first two steps are importing the dataset and pre-processing the data. Inpre-processingofthe data we remove orreplace the missing values in the dataset before applying it to a supervisedmachinelearningalgorithm then the cross-validation techniqueis applied. The attributes selected from the dataset [10] are very simple and are regularly taken duringthemedicalexamination of a patient. This is done mainly to keep the cost of heart disease prediction low. Age andsexbotharethe personal information of the patient. Blood pressure and the chest pain can be examined by doctor withoutanyadditional requirement of the test. For attribute such as fasting blood sugar, blood test is requiredandforexamining attributes such as slope and old peak ST, ECG is needed. So maximum attributes usedinthesystemareobtained by normal testing of patient. No expensive tests are needed for predication, hence thesystemiscost-effective.\par
In Cleveland Heart disease dataset for six instances some values are missing. The remaining 297 instances have completevalues. Hencemost of the researchers use the 297 instance values for prediction of heart disease. For machine learning size of the data set isanimportantpoint for the accuracy of the model. Bigger size dataset with data without noise and data with no missing values are usefullyreliable.Butwe face problem if the dataset size is small. For better accuracy, more pattern in the dataset should be explored. The cross-validationisused for it. For any supervise Machine Learning algorithm dataset is divided in two-parts: first one is training part and the secondoneisthetestingpart. Commonly training size is 70% and testing size is 30% but for special analysis size may vary. In general trainingusinglargeramount of data and testing against a small amount of data account for accuracy of a ML algorithm. As shown in Fig. 2, the first two steps are importing the dataset and pre-processing the data. In pre-processing of the datatheyremoveorreplace the missing values in the dataset before applying it to a supervised machine learning algorithm then the cross-validationtechniqueis applied. The attributes selected from the dataset [10] are very simple and are regularly taken during the medical examination of apatient. Thisisdone mainly to keep the cost of heart disease prediction low. Age and sex both are the personal information of the patient. Bloodpressureand the chest pain can be examined by doctor without any additional requirement of the test. For attribute such as fastingbloodsugar,\par
blood test is required and for examining attributes such as slope and old peak ST, ECG is needed. So maximumattributesusedinthesystem are obtained by normal testing of patient. No expensive tests are needed for predication, hence the systemis cost-effective. Table 1: Dataset description [10]\par
\f2 Predication with supervised machine learning is done by dividing the dataset in two sets: independent and dependent attributes. Firstsetof attributes, the independent attributes are the ones whose value does not depend on the value of other attributes. In the dataset, first13attributes are independent attributes. The last one, which is commonly called as a class or the target attribute is a dependableattribute.Itsvalue depends on the other independent attributes. In our case target is the last attribute which talks about having a heart diseaseornothaving a heart disease. 2. LITERATURE SURVEY\par
The literature survey consists of first four papers surveyed from medical background. They are studied to establish theimportanceofvarious features and their typical values. Being from medical background, no machine learning algorithms is applied for theheartdiseasedetection and hence are not included in the survey table (Table 3). The literature survey after these four papers is fromengineeringbackground where different features are considered and various machine learning algorithms are applied for automaticdetectionofpresence of heart disease. The numbers in the square bracket below corresponds to the numbers mentioned in the \lquote References\rquote . [1] In this paper the authors talk about Atherosclerotic Cardiovascular disease (CVD) which is age dependent. AtheroscleroticCVDstartsat a very young age and progresses over time. Age is the traditional non-modifiable factor in heart disease. The risk of heart diseaseishigh during the lifetime, but, at the age of 70 years it gets reduced as compared to the risk at the age of 50 years. It alsodependsonotherrisk factors that remain unchanged in the life such as smoking and drinking a lot of alcohol.\par
Age group 70 and above have a shorter period of time left to develop the disease due to lower burden on cardiovascular systemanddueto their genetic makeup. It indicates that heart disease is a function of age and the risk is lower at the age of 70 and above but higheratagegroup 32 \endash  62. [2] In this, the authors deal with the impact of gender on heart disease basically comparison between male and female. Heartdiseasedevelops in the female 7 to 10 years late than the male which implies that male can get the heart disease earlier than female. But stillthemajor reason for death in female above 65 years is heart disease. Past twenty years the heart disease midlife (35 to 54years) forwomenhas increased. Why women are more protected to heart disease than men? The answer is \lquote Estrogen\rquote  hormone. It is a hormone secretedbyovaries.Estrogen regulates the metabolic activity of lipids, inflammatory markers and the coagulant system. Effect of the vasodilatoryactionisreduced risk of atherosclerosis. Early menopause increases the risk of heart disease and it is observed that the early menopausewomenhave two years less life than the normal or late menopause women. Smoking at an early age less than 50 years affects more in women than men and it also increases acute myocardial infarctioninfemalesthan in men. After menopause normal body weight increase in the first few years. Increased weight and increased changes of diabetestype2itisobserved that female with diabetes are 50% at more risk to heart disease than men. During menopause total cholesterol and low-density lipoprotein (LDL) levels rise 10 to 14% and HDL remain the same. Systolicbloodpressure increases rapidly in menopaused women as compared to the same age of men. [3] In this paper author\rquote s deal with two risk factors blood pressure and cholesterol. Let\rquote s first consider blood pressure. Normal andnormalhigh consider as normal for a person but the normal high person has to take care of himself as the normal high may get convertedtohypertension in near future. The Hypertension stages are from one to four and are given in table 2 below. As we have already seen above, age act as a major factor in heart disease as with others such as high BP, high cholesterol, chestpain,high sugar level. Bad habits such as drinking a lot of alcohol and smoking, unhealthy lifestyle, lack of body activity results inmoreriskofheart disease. The habits such as smoking and drinking cause the thickness and stiffness of the vessel resulting into major probleminthecirculation of blood and have adverse \f1\par
The second factor is cholesterol. Cholesterol is of two types: HDL and LDL, both together is called total Cholesterol. Fornormalperson 200mg/dl is considered normal. For borderline it is in the range 200 to 239 mg/dl more than this value is consideredasthehighvalue of Cholesterol. High value means a high risk of heart disease. High-density lipoprotein (HDL) cholesterol is alsoknownasgoodcholesterol because it helps to remove other forms of cholesterol from serum. A higher level of HDL means a lowriskof heart disease.For men the value of HDL less than 40mg/dl and for women less than 50mg/dl indicates the risk of heart disease. Normal valueformenand women is min 60mg/dl. More than 60mg/dl indicates less risk of heart disease obviously. Low-density lipoprotein (LDL) is also called bad cholesterol because it gets deposited on the walls of blood vessels. Due tothis, thebloodvessels get narrow and blood pressure increases on the walls of the blood vessels. Indirectly LDL increase the risk of heart disease. LDL normal level is considered between 100 to 129 mg/dl for a normal person. From 130 to 159 mg/dl is called borderlinehigh.Morethan that called to higher 160 to 189 mg/dl and very high 190 and above. Both higher and very higher are considered tobeariskforheartdisease. So from [2] and [3] we can conclude that gender, cholesterol levels and blood pressure values play an important role indetectionofheart disease and hence should be considered as features for the detection system. [4] In this paper authors deal with ST-segment depression during treadmill electrocardiography (ECG). For this study, 150numberofsubjects were selected with a low likelihood of coronary heart disease (out of hundred are normal and 50 with non-anginal chest pain)andanother group 150 subjects was selected with a high likelihood of coronary heart disease. The total 300 subjects are then divided into four groups and are made to do the treadmill exercise. First group is of 100 normal subjects i.e. with low likelihood of coronary heart disease. There were 81 men and 19 womenwithanagebetween 47-60 years. It was observed that there was no chest pain during treadmill exercise. Second group subjects are with non-anginal chest pain. They are 50 in number with 33 men and 17 female with age rangingbetween47-60 years. It was observed that even there was no chest pain in these subjects during treadmill exercise. Group 3 was with subjects having history of clinical angina. There were 50 subjects with 31 men and 19 female havingagerange61-71years. All the subjects in this group developed typical chest pain during treadmill exercise. Fourth group subjects were with catheterization-proved coronary disease. They are 100 in number with 84 male and 16 femalehavingagegroup between 58-67 years. For all groups ECG was taken. The sensitivity of an ST segment/heart rate slope partition of 2.4 \'b5V/beats/min was 95%andthesensitivity of a \f3\u8710?\f1 ST segment/heart rate index partition of 1.6\'b5V/beats/min was 91%. Analysis of \f3\u8710?\f1 ST segment/heart rateindexandST\par
segment depression can markedly improve the clinical usefulness of the treadmill exercise and ECG. It can be concludedingeneralthatifthe ST slop < 2.4, then the person is not having a heart disease and if ST slope > 2.4 then the person can have a heart disease. [5] In this paper authors used two algorithms: hill climbing and decision tree. Before applying the classification algorithms, thedataispre-processed. The data set used is Cleveland data set. The Knowledge Extraction is done based on Evolutionary Learning(KEEL),anopen-source data mining tool which is used to fill the missing values in the data set. Hill climbing algorithmis then usedtofindthebestsubset of rules. The parameters and their values used are - Confidence: minimum confidence value is 0.25, MinItemsets: theminimumnumber of item-sets per leaf is two, Threshold: a value of 10 is used to find the best subset of rules for the hill-climbingalgorithmbytheauthors. A decision tree is constructed in the top-down approach for each level and a node is selected by a test for the actual nodechosenusingahill-climbing algorithm. The decision tree knows how to generate the basic rules. First generated rules are referred to as original rulesandfrom these rules Pruned Rules are generated. From these rules without duplicates and classified rules are obtained. Andfinallyasmallnumber of rules called Class wise Rule distribution is generated. The accuracy of the system is about 86.7%. [6] In this paper author has implemented hybrid machine learning for heart disease prediction. The data set used is Clevelanddataset.The first step is data pre-processing step. In this the tuples are removed from the data set which have missing the values. Attributesageand sex from data set are also not used as the authors think that it\rquote s personal information and has no impact on predication. Theremaining11 attributes are considered important as they contain vital clinical records. They have proposed own Hybrid RandomForestLinearMethod (HRFLM) which is combination of Random Forest (RF) and Linear method (LM). In HRFLM algorithm the authors have used four algorithms. First algorithm deals with partitioning the input dataset. It isbasedondecision tree which is executed for each sample of the dataset. After identifying the feature space, the dataset is split intotheleafnodes.Output of first algorithm is Partition of data set. After that in second algorithm they apply rules to the data set and output hereistheclassification of data with those rules. In third algorithm features are extracted using Less Error Classifier. This algorithmdealswithfinding the minimum and maximum error rate from the classifier. Output of this algorithm is the features with classifiedattributes.Inforth algorithm they apply Classifier which is hybrid method based on the error rate on the Extracted Features. Finallytheyhavecompared the results obtained after applying HRFLM with other classification algorithms such as decision tree andsupportvectormachine. In result as RF and LM are giving better results than other, both the algorithms are put together and new unique algorithmHRFLMiscreated. The accuracy of HRFLM initially increased with number splits and then has become constant at a particular level. Theaccuracyobtained is 88.7% which higher than the SVM and decision tree. The authors suggest further improvement in accuracybyusingcombination of various machine learning algorithms and also by concentrating on developing novel feature selectiontechniqueswhichwould help in extracting significant features. [7] In this paper, the authors propose a system containing two models based on linear Support Vector Machine (SVM). Thefirstoneiscalled L1 regularized and the second one is called L2 regularized. First model is used for removing unnecessary featuresbymakingcoefficient of those features zero. The second model is used for prediction. Predication of disease is done in this part. Tooptimizebothmodels they proposed a hybrid grid search algorithm. This algorithm optimizes two models based on metrics: accuracy, sensitivity,septicity, the Matthews correlation coefficient, ROC chart and area under the curve. They used Cleveland data set. Data splits into 70% training and 30% testing used holdout validation. There are two experimentscarriedout and each experiment is carried out for various values of C1, C2 and k where C1 is hyperparameter of L1 regularizedmodel,C2ishyperparameter of L2 regularized model and k is the size of selected subset of features. First experiment is L1-linear SVMmodelstackedwith L2-linear SVM model which is giving maximum testing accuracy of 91.11% and training accuracy of 84.05%for valueofC1=0.200, k = 11 and C2 = 0.500. The second experiment is L1-linear SVM model cascaded with L2-linear SVMmodel withRBFkernel.This is giving maximum testing accuracy of 92.22% and training accuracy of 85.02% for value of C1 = 0.060, k = 8 andC2=400.00andG (Hyperparameter of the L2-SVM model with RBF kernel) = 0.015. They have obtained an improvement in accuracy over conventionalSVM models by 3.3%. [8] In this paper authors deal with various supervised machine learning algorithms such as Random Forest, Support VectorMachine,Logistic Regression, Linear Regression, Decision Tree with 3 fold, 5 fold and 10 fold cross-validation techniques. They have used Cleveland data set having 303 tuples, with some tuples having missing attributes. In the preprocessingof datatheyjustremoved the missing value tuple from the data set which are six in number and then from the remaining 297 tuples, theydividedthedataas training 70% and testing 30%. First algorithm applied is Linear Regression. In this, they have defined the dependency of one attribute over others whichcanbelinearlyseparated from each other. Basically the classification takes place with the help of the group of attributes used for binaryclassification.They have obtained best results in 10 fold which is 83.82%. Logistic regression classification is done using a sigmoidfunction.Thisalgorithm applied for heart disease prediction shows maximum accuracy with 3 and 5 fold cross-validation and it is 83.83%. SupportVector Machine is the classification algorithm in supervised machine learning. In this the classification is done byhyperplane.Themaximum accuracy achieved by SVM in 3 fold cross-validation is 83.17%. For Decision Tree in this paper, the authors have used different number splits and different number of leaf nodes to findthemaximumaccuracy. With 37 number splits and 6 leaf nodes maximum accuracy is achieved which is 79.12%. When used withcross-validation,accuracy achieved by the decision tree 79.54% with 5 fold. Random forest algorithm used on nonlinear data set gives betterresultsascompared to the decision tree. Random forest is the group of decision tree created by the different root nodes. Fromthis groupofdecisiontree, voting can be done first and then classification can be done from the one getting maximum votes. Authors haveuseddifferentnumber splits, different number of tree per observation and different number of folds for cross-validation. For randomforest, 85.81%accuracy is achieved by 20 Number of splits, 75 Number of trees and 10 number of folds.\par
[9] In this paper authors deal with machine learning algorithms such as decision tree and Naive Bayes algorithmfor predictionofheartdisease. In first algorithm the decision tree is built using certain conditions which gives True or False decisions. Other algorithmslikeSVM, KNN are results based on vertical or horizontal split conditions depends on dependent variables. But decision treefor atreelikestructure having root node, leaves and branches base on the decision made in each of tree Decision tree also help in the understatingtheimportance of the attributes in the dataset. They have also used Cleveland data set. Dataset splits in 70% training and 30% testing. This algorithm gives a 91%accuracy. The second algorithm is Naive Bayes. It is used for classification. It can handle complicated, nonlinear, dependent data andhenceisfoundsuitable for heart disease dataset as this dataset is also complicated, dependent and nonlinear in nature. This algorithmgivesan87%accuracy. Table 3: Survey Table\par
In this paper, we surveyed on two things: the first part of the study is finding important factors affecting the heart disease, theimportantattributes and their minimum support values for no heart disease. Then use of machine learning algorithmfor predictionof heart disease.From risk factors we have selected number of attributes and their minimum value for normal and diseased person. Values of theattributesmore than the minimum value means you have a risk of heart disease. That means a person who have diabetes, smokinghabit last10years, hypertension, chest pain, ST-T depression, older age more than 60 years, women with early menopause, over dirking, highervaluesof cholesterol more than 200mg/dl and person with blockage in heart vessels are more likely to be the heart disease person. Second part of the studies of supervised machine algorithms for prediction of heart disease. In this various algorithmsstudiedareSupport vector machine, Decision tree, Random forest, Linear regression and Naive Bayes classifier. Lots of work is doneinthisarea.The dataset is quite old and has no new attributes added in it. There is no cleaning and pruning of data. Uncleaned andmissingvaluesinthe dataset has no use for classification and prediction. Moreover, no one has worked on the size of the dataset. The small sizeofthedataset is a problem for machine learning algorithms. Large size of the dataset is needed for better prediction. REFERENCES\par
[1] Dhingra, Ravi, and Ramachandran S. Vasan, "Biomarkers in cardiovascular disease: Statistical assessment and sectiononkeynovelheart failure biomarkers." Trends in cardiovascular medicine 27.2 (2017): 123-133. [2] Maas, Angela HEM, and Yolande EA Appelman. "Gender differences in coronary heart disease." Netherlands Heart Journal18.12(2010): 598-603\par
[3] Wilson, Peter WF, et al, "Prediction of coronary heart disease using risk factor categories." Circulation 97.18 (1998): 1837-1847.[4] Kligfield, Paul, Olivier Ameisen, and P. M. Okin. "Heart rate adjustment of ST segment depression for improved detectionofcoronaryartery disease." Circulation 79.2 (1989): 245-255. [5] Purushottam, Kanak Saxena and Richa Sharma, "Efficient heart disease prediction system." Procedia Computer Science85(2016):962-969. [6] Mohan, Senthilkumar, Chandrasegar Thirumalai, and Gautam Srivastava, "Effective heart disease prediction usinghybridmachinelearning techniques." IEEE Access 7 (2019): 81542-81554. Ali, Liaqat, et al, "An optimized stacked support vector machines based expert system for the effective prediction of heart failure."`\lang9\par
}
 